{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJ+dwCTYQ3lRD/AvlA7P5q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amelbnmbh/Introduction-to-Big-Data-with-Spark-and-Hadoop/blob/main/Introduction_to_SparkSQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction to SparkSQL**\n",
        "## Objectives\n",
        "Spark SQL is a Spark module for structured data processing. It is sed to query structured data inside Spark programs, using either SQL or a familiar DataFrame API.\n",
        "\n",
        "After completing this lab you will be able to:\n",
        "* Load a data file into a dataframe\n",
        "* Create a Table View for the dataframe\n",
        "* Run basic SQL queries and aggregate data on the table view\n",
        "* Create a Pandas UDF to perform columnar operations\n",
        "----\n",
        "\n",
        "## Setup\n",
        "\n"
      ],
      "metadata": {
        "id": "QFkSKQPD0LrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing required packages\n",
        "!pip install pyarrow\n",
        "!pip install findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ii3ggGkc0j1V",
        "outputId": "99cb413b-3cce-4b5f-e5d3-54eb91fe3bb6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (17.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.26.4)\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n",
            "Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "cMR7bwlC00_k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "RFZJXr6T02mu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1 -  Spark session\n",
        "Create and initialize the Spark session needed to load the data frames and operate on it\n",
        "\n",
        "#### Task 1: Creating the spark session and context\n"
      ],
      "metadata": {
        "id": "qZldkAzA1B2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a spark context class\n",
        "sc = SparkContext()\n",
        "\n",
        "# Creating a spark session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark DataFrames basic example\") \\\n",
        "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "HZl6fbDy1FJf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 2: Initialize Spark session\n",
        "To work with dataframes we just need to verify that the spark session instance has been created.\n"
      ],
      "metadata": {
        "id": "ebDgrji-1KnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "kI9_F7cJ1MvB",
        "outputId": "5ce6e4bc-4f05-40ec-ad5d-418e0aaea137"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f7cd1a3bb20>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://69683a5cda36:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2 - Loading the Data and creating a table view\n",
        "In this section, we will first read the CSV file into a Pandas Dataframe and then read it into a Spark Dataframe\n",
        "\n",
        "To create a Spark DataFrame we load an external DataFrame, called `mtcars`. This DataFrame includes 32 observations on 11 variables:\n",
        "\n",
        "| colIndex | colName | units/description |\n",
        "| :---: | :--- | :--- |\n",
        "|[, 1] | mpg |Miles per gallon  |\n",
        "|[, 2] | cyl | Number of cylinders  |\n",
        "|[, 3] | disp | Displacement (cu.in.) |  \n",
        "|[, 4] | hp  | Gross horsepower  |\n",
        "|[, 5] | drat | Rear axle ratio  |\n",
        "|[, 6] | wt | Weight (lb/1000)  |\n",
        "|[, 7] | qsec | 1/4 mile time  |\n",
        "|[, 8] | vs  | V/S  |\n",
        "|[, 9] | am | Transmission (0 = automatic, 1 = manual)  |\n",
        "|[,10] | gear | Number of forward gears  |\n",
        "|[,11] | carb | Number of carburetors |\n",
        "\n",
        "#### Task 1: Load data into a Pandas DataFrame.\n",
        "\n",
        "Pandas has a convenient function to load CSV data from a URL directly into a pandas dataframe.\n",
        "\n"
      ],
      "metadata": {
        "id": "qKEUTSWy1PlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the file using `read_csv` function in pandas\n",
        "mtcars = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/labs/data/mtcars.csv')"
      ],
      "metadata": {
        "id": "6qWTxb5S1c6Q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview a few records\n",
        "mtcars.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yQvQ1Ngw1goq",
        "outputId": "46b59d75-b4cf-4c4e-daa5-d6d103a663f2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Unnamed: 0   mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  \\\n",
              "0          Mazda RX4  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4   \n",
              "1      Mazda RX4 Wag  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4   \n",
              "2         Datsun 710  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4   \n",
              "3     Hornet 4 Drive  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3   \n",
              "4  Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3   \n",
              "\n",
              "   carb  \n",
              "0     4  \n",
              "1     4  \n",
              "2     1  \n",
              "3     1  \n",
              "4     2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e4dc42e-5fba-4ec6-8685-438471ea01e8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>mpg</th>\n",
              "      <th>cyl</th>\n",
              "      <th>disp</th>\n",
              "      <th>hp</th>\n",
              "      <th>drat</th>\n",
              "      <th>wt</th>\n",
              "      <th>qsec</th>\n",
              "      <th>vs</th>\n",
              "      <th>am</th>\n",
              "      <th>gear</th>\n",
              "      <th>carb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mazda RX4</td>\n",
              "      <td>21.0</td>\n",
              "      <td>6</td>\n",
              "      <td>160.0</td>\n",
              "      <td>110</td>\n",
              "      <td>3.90</td>\n",
              "      <td>2.620</td>\n",
              "      <td>16.46</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mazda RX4 Wag</td>\n",
              "      <td>21.0</td>\n",
              "      <td>6</td>\n",
              "      <td>160.0</td>\n",
              "      <td>110</td>\n",
              "      <td>3.90</td>\n",
              "      <td>2.875</td>\n",
              "      <td>17.02</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Datsun 710</td>\n",
              "      <td>22.8</td>\n",
              "      <td>4</td>\n",
              "      <td>108.0</td>\n",
              "      <td>93</td>\n",
              "      <td>3.85</td>\n",
              "      <td>2.320</td>\n",
              "      <td>18.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hornet 4 Drive</td>\n",
              "      <td>21.4</td>\n",
              "      <td>6</td>\n",
              "      <td>258.0</td>\n",
              "      <td>110</td>\n",
              "      <td>3.08</td>\n",
              "      <td>3.215</td>\n",
              "      <td>19.44</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hornet Sportabout</td>\n",
              "      <td>18.7</td>\n",
              "      <td>8</td>\n",
              "      <td>360.0</td>\n",
              "      <td>175</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.440</td>\n",
              "      <td>17.02</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e4dc42e-5fba-4ec6-8685-438471ea01e8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1e4dc42e-5fba-4ec6-8685-438471ea01e8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1e4dc42e-5fba-4ec6-8685-438471ea01e8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aaccf239-ac70-425f-8360-c95af56cb675\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aaccf239-ac70-425f-8360-c95af56cb675')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aaccf239-ac70-425f-8360-c95af56cb675 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "mtcars",
              "summary": "{\n  \"name\": \"mtcars\",\n  \"rows\": 32,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"Ferrari Dino\",\n          \"Lincoln Continental\",\n          \"Pontiac Firebird\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mpg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.026948052089105,\n        \"min\": 10.4,\n        \"max\": 33.9,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          17.8,\n          33.9,\n          21.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cyl\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 4,\n        \"max\": 8,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6,\n          4,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"disp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 123.93869383138194,\n        \"min\": 71.1,\n        \"max\": 472.0,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          275.8,\n          75.7,\n          472.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 68,\n        \"min\": 52,\n        \"max\": 335,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          110,\n          52,\n          180\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"drat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5346787360709716,\n        \"min\": 2.76,\n        \"max\": 4.93,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          3.9,\n          4.93,\n          3.07\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9784574429896967,\n        \"min\": 1.513,\n        \"max\": 5.424,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          2.77,\n          1.615,\n          5.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"qsec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7869432360968431,\n        \"min\": 14.5,\n        \"max\": 22.9,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          15.5,\n          17.42,\n          17.05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"am\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gear\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"carb\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 8,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mtcars.rename( columns={'Unnamed: 0':'name'}, inplace=True )"
      ],
      "metadata": {
        "id": "dE88ZDZo1jCd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 2: Loading data into a Spark DataFrame\n",
        "\n",
        "We use the `createDataFrame` function to load the data into a spark dataframe\n",
        "\n"
      ],
      "metadata": {
        "id": "KuRG_qj91ndh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sdf = spark.createDataFrame(mtcars)"
      ],
      "metadata": {
        "id": "zmPWK3UW1rgn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us look at the schema of the loaded spark dataframe\n"
      ],
      "metadata": {
        "id": "8EAMWwnN1RW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sdf.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XYc4kfK1wKt",
        "outputId": "e70ff5e0-3317-4d5a-cc67-338f31cb53ce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- mpg: double (nullable = true)\n",
            " |-- cyl: long (nullable = true)\n",
            " |-- disp: double (nullable = true)\n",
            " |-- hp: long (nullable = true)\n",
            " |-- drat: double (nullable = true)\n",
            " |-- wt: double (nullable = true)\n",
            " |-- qsec: double (nullable = true)\n",
            " |-- vs: long (nullable = true)\n",
            " |-- am: long (nullable = true)\n",
            " |-- gear: long (nullable = true)\n",
            " |-- carb: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 3: Rename the existing column name \"vs\" to \"versus\" and assign the new result DataFrame to a variable, \"sdf_new\".\n",
        "\n",
        "The function `withColumnRenamed()` is renames the existing column names.  \n",
        "\n"
      ],
      "metadata": {
        "id": "NnOLrC7g10Xl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sdf_new = sdf.withColumnRenamed(\"vs\", \"versus\")"
      ],
      "metadata": {
        "id": "f0luHKYU1z0J"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The execution of the above function doesn’t modify the original DataFrame `sdf`, instead, a new DataFrame `sdf_new` is created with the renamed column.\n"
      ],
      "metadata": {
        "id": "9U-11T9c15Wo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Task 4: View the new dataframe\n"
      ],
      "metadata": {
        "id": "EJL6Te5b17dP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sdf_new.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60VP2ghS18-O",
        "outputId": "6aef741c-5fc8-43a1-e273-2a43220c7849"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----+---+-----+---+----+-----+-----+------+---+----+----+\n",
            "|             name| mpg|cyl| disp| hp|drat|   wt| qsec|versus| am|gear|carb|\n",
            "+-----------------+----+---+-----+---+----+-----+-----+------+---+----+----+\n",
            "|        Mazda RX4|21.0|  6|160.0|110| 3.9| 2.62|16.46|     0|  1|   4|   4|\n",
            "|    Mazda RX4 Wag|21.0|  6|160.0|110| 3.9|2.875|17.02|     0|  1|   4|   4|\n",
            "|       Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|     1|  1|   4|   1|\n",
            "|   Hornet 4 Drive|21.4|  6|258.0|110|3.08|3.215|19.44|     1|  0|   3|   1|\n",
            "|Hornet Sportabout|18.7|  8|360.0|175|3.15| 3.44|17.02|     0|  0|   3|   2|\n",
            "+-----------------+----+---+-----+---+----+-----+-----+------+---+----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 4: Create a Table View\n",
        "Creating a table view in Spark SQL is required to run SQL queries programmatically on a DataFrame. A view is a temporary table to run SQL queries. A Temporary view provides local scope within the current Spark session. In this example we create a temporary view using the `createTempView()` function\n"
      ],
      "metadata": {
        "id": "_JiN9lLz2IL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sdf.createTempView(\"cars\")"
      ],
      "metadata": {
        "id": "hXADIGLj2JmK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3 - Running SQL queries and aggregating data\n",
        "Once we have a table view, we can run queries similar to querying a SQL table. We perform similar operations to the ones in the DataFrames notebook. Note the difference here however is that we use the SQL queries directly.\n"
      ],
      "metadata": {
        "id": "oxkQxFoQ2U_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Showing the whole table\n",
        "spark.sql(\"SELECT * FROM cars\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qMY0LG02Xc7",
        "outputId": "5c5facf4-332a-4fc6-d42d-733d03003cc7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
            "|               name| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|\n",
            "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
            "|          Mazda RX4|21.0|  6|160.0|110| 3.9| 2.62|16.46|  0|  1|   4|   4|\n",
            "|      Mazda RX4 Wag|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|   4|\n",
            "|         Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|\n",
            "|     Hornet 4 Drive|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|   1|\n",
            "|  Hornet Sportabout|18.7|  8|360.0|175|3.15| 3.44|17.02|  0|  0|   3|   2|\n",
            "|            Valiant|18.1|  6|225.0|105|2.76| 3.46|20.22|  1|  0|   3|   1|\n",
            "|         Duster 360|14.3|  8|360.0|245|3.21| 3.57|15.84|  0|  0|   3|   4|\n",
            "|          Merc 240D|24.4|  4|146.7| 62|3.69| 3.19| 20.0|  1|  0|   4|   2|\n",
            "|           Merc 230|22.8|  4|140.8| 95|3.92| 3.15| 22.9|  1|  0|   4|   2|\n",
            "|           Merc 280|19.2|  6|167.6|123|3.92| 3.44| 18.3|  1|  0|   4|   4|\n",
            "|          Merc 280C|17.8|  6|167.6|123|3.92| 3.44| 18.9|  1|  0|   4|   4|\n",
            "|         Merc 450SE|16.4|  8|275.8|180|3.07| 4.07| 17.4|  0|  0|   3|   3|\n",
            "|         Merc 450SL|17.3|  8|275.8|180|3.07| 3.73| 17.6|  0|  0|   3|   3|\n",
            "|        Merc 450SLC|15.2|  8|275.8|180|3.07| 3.78| 18.0|  0|  0|   3|   3|\n",
            "| Cadillac Fleetwood|10.4|  8|472.0|205|2.93| 5.25|17.98|  0|  0|   3|   4|\n",
            "|Lincoln Continental|10.4|  8|460.0|215| 3.0|5.424|17.82|  0|  0|   3|   4|\n",
            "|  Chrysler Imperial|14.7|  8|440.0|230|3.23|5.345|17.42|  0|  0|   3|   4|\n",
            "|           Fiat 128|32.4|  4| 78.7| 66|4.08|  2.2|19.47|  1|  1|   4|   1|\n",
            "|        Honda Civic|30.4|  4| 75.7| 52|4.93|1.615|18.52|  1|  1|   4|   2|\n",
            "|     Toyota Corolla|33.9|  4| 71.1| 65|4.22|1.835| 19.9|  1|  1|   4|   1|\n",
            "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Showing a specific column\n",
        "spark.sql(\"SELECT mpg FROM cars\").show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cukjigly2eO6",
        "outputId": "484a1d72-5c1a-4304-dccb-2150b98c01d6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+\n",
            "| mpg|\n",
            "+----+\n",
            "|21.0|\n",
            "|21.0|\n",
            "|22.8|\n",
            "+----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic filtering query to determine cars that have a high mileage and low cylinder count\n",
        "spark.sql(\"SELECT * FROM cars where mpg>20 AND cyl < 6\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uObkO-iG2irg",
        "outputId": "59ef524c-cef0-4c08-e096-e220bbe9cb7c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
            "|       name| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|\n",
            "+-----------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
            "| Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|\n",
            "|  Merc 240D|24.4|  4|146.7| 62|3.69| 3.19| 20.0|  1|  0|   4|   2|\n",
            "|   Merc 230|22.8|  4|140.8| 95|3.92| 3.15| 22.9|  1|  0|   4|   2|\n",
            "|   Fiat 128|32.4|  4| 78.7| 66|4.08|  2.2|19.47|  1|  1|   4|   1|\n",
            "|Honda Civic|30.4|  4| 75.7| 52|4.93|1.615|18.52|  1|  1|   4|   2|\n",
            "+-----------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregating data and grouping by cylinders\n",
        "spark.sql(\"SELECT count(*), cyl from cars GROUP BY cyl\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SEMOMl-2qsZ",
        "outputId": "92fb961c-2042-4c49-f913-b75127649ebd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+\n",
            "|count(1)|cyl|\n",
            "+--------+---+\n",
            "|       7|  6|\n",
            "|      14|  8|\n",
            "|      11|  4|\n",
            "+--------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 4 - Create a Pandas UDF to apply a columnar operation\n",
        "Apache Spark has become the de-facto standard in processing big data. To enable data scientists to leverage the value of big data, Spark added a Python API in version 0.7, with support for user-defined functions (UDF). These user-defined functions operate one-row-at-a-time, and thus suffer from high serialization and invocation overhead. As a result, many data pipelines define UDFs in Java and Scala and then invoke them from Python.\n",
        "\n",
        "Pandas UDFs built on top of Apache Arrow bring you the _best of both worlds_—the ability to define low-overhead, high-performance UDFs entirely in Python. In this simple example, we will build a Scalar Pandas UDF to convert the wT column from imperial units (1000-lbs) to metric units (metric tons).\n",
        "\n",
        "In addition, UDFs can be registered and invoked in SQL out of the box by registering a regular python function using the `@pandas_udf()` decorator. We can then apply this UDF to our `wt` column.\n",
        "\n",
        "#### Task 1: Importing libraries and registering a UDF\n",
        "\n"
      ],
      "metadata": {
        "id": "EeIzeA4526-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the Pandas UDF function\n",
        "from pyspark.sql.functions import pandas_udf, PandasUDFType"
      ],
      "metadata": {
        "id": "wmWV4XtO2-FD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@pandas_udf(\"float\")\n",
        "def convert_wt(s: pd.Series) -> pd.Series:\n",
        "    # The formula for converting from imperial to metric tons\n",
        "    return s * 0.45\n",
        "\n",
        "spark.udf.register(\"convert_weight\", convert_wt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5iuyZt73AN6",
        "outputId": "2e3d32e0-f018-4a83-a42c-39c9c1adbc9b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.udf.UserDefinedFunction at 0x7f7cd04df130>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 2: Applying the UDF to the tableview\n",
        "\n",
        "We can now apply the `convert_weight` user-defined-function to our `wt` column from the `cars` table view. This is done very simply using the SQL query shown below. In this example below we show both the original weight (in ton-lbs) and converted weight (in metric tons).\n"
      ],
      "metadata": {
        "id": "G7wPPpRq3FOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT *, wt AS weight_imperial, convert_weight(wt) as weight_metric FROM cars\").show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvv0wLHx3GhI",
        "outputId": "5c614bec-bb4f-4602-a52a-75098d2cccb4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----+---+-----+---+----+-----+-----+---+---+----+----+---------------+-------------+\n",
            "|         name| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|weight_imperial|weight_metric|\n",
            "+-------------+----+---+-----+---+----+-----+-----+---+---+----+----+---------------+-------------+\n",
            "|    Mazda RX4|21.0|  6|160.0|110| 3.9| 2.62|16.46|  0|  1|   4|   4|           2.62|        1.179|\n",
            "|Mazda RX4 Wag|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|   4|          2.875|      1.29375|\n",
            "|   Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|           2.32|        1.044|\n",
            "+-------------+----+---+-----+---+----+-----+-----+---+---+----+----+---------------+-------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 5 - Combining DataFrames based on a specific condition.\n",
        "\n",
        "#### Task 1 - Understanding JOIN operation\n"
      ],
      "metadata": {
        "id": "kGerEwDA3Rtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define sample DataFrame 1\n",
        "\n",
        "data = [(\"A101\", \"John\"), (\"A102\", \"Peter\"), (\"A103\", \"Charlie\")]\n",
        "\n",
        "columns = [\"emp_id\", \"emp_name\"]\n",
        "\n",
        "dataframe_1 = spark.createDataFrame(data, columns)"
      ],
      "metadata": {
        "id": "rWbPOQxY3XDA"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define sample DataFrame 2\n",
        "\n",
        "data = [(\"A101\", 3250), (\"A102\", 6735), (\"A103\", 8650)]\n",
        "\n",
        "columns = [\"emp_id\", \"salary\"]\n",
        "\n",
        "dataframe_2 = spark.createDataFrame(data, columns)"
      ],
      "metadata": {
        "id": "mZgStHa53ZXO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new DataFrame, \"combined_df\" by performing an inner join\n",
        "\n",
        "combined_df = dataframe_1.join(dataframe_2, on=\"emp_id\", how=\"inner\")"
      ],
      "metadata": {
        "id": "dmJAFpWX3a_k"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the data in combined_df as a list of Row.\n",
        "\n",
        "combined_df.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsyrWpXt3cV5",
        "outputId": "45063757-495b-43ff-e4a2-43be4cf20d71"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(emp_id='A101', emp_name='John', salary=3250),\n",
              " Row(emp_id='A102', emp_name='Peter', salary=6735),\n",
              " Row(emp_id='A103', emp_name='Charlie', salary=8650)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4vOjWr93fhb",
        "outputId": "60fdc85b-d579-4381-a13e-9f9e162773a6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(emp_id='A101', emp_name='John', salary=3250)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUun14zF3k-3",
        "outputId": "a151c2c3-18f8-493d-a982-86fdee3b2b15"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+------+\n",
            "|emp_id|emp_name|salary|\n",
            "+------+--------+------+\n",
            "|  A101|    John|  3250|\n",
            "|  A102|   Peter|  6735|\n",
            "|  A103| Charlie|  8650|\n",
            "+------+--------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 2 Filling the missing values\n"
      ],
      "metadata": {
        "id": "fGzvRe953pK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define sample DataFrame 1 with some missing values\n",
        "\n",
        "data = [(\"A101\", 1000), (\"A102\", 2000), (\"A103\",None)]\n",
        "\n",
        "columns = [\"emp_id\", \"salary\"]\n",
        "\n",
        "dataframe_3 = spark.createDataFrame(data, columns)\n"
      ],
      "metadata": {
        "id": "ZR2-smkY3qU9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fill missing salary value with a specified value\n",
        "filled_df = dataframe_3.fillna({\"salary\": 3000})\n",
        "dataframe_3.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1R08hu03uNX",
        "outputId": "518ab402-487f-4c56-f5d2-3b5835a7cbfc"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(emp_id='A101', salary=1000),\n",
              " Row(emp_id='A102', salary=2000),\n",
              " Row(emp_id='A103', salary=None)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1 - Basic SQL operations\n",
        "Display all Mercedez car rows from the `cars` table view we created earlier. The Mercedez cars have the prefix \"Merc\" in the car name column.\n"
      ],
      "metadata": {
        "id": "FCivbBgN34XX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT * FROM cars where name like 'Merc%'\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxdhLJ_Z36X_",
        "outputId": "762a3ce5-3d11-42df-af63-60b2718c68a9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----+---+-----+---+----+----+----+---+---+----+----+\n",
            "|       name| mpg|cyl| disp| hp|drat|  wt|qsec| vs| am|gear|carb|\n",
            "+-----------+----+---+-----+---+----+----+----+---+---+----+----+\n",
            "|  Merc 240D|24.4|  4|146.7| 62|3.69|3.19|20.0|  1|  0|   4|   2|\n",
            "|   Merc 230|22.8|  4|140.8| 95|3.92|3.15|22.9|  1|  0|   4|   2|\n",
            "|   Merc 280|19.2|  6|167.6|123|3.92|3.44|18.3|  1|  0|   4|   4|\n",
            "|  Merc 280C|17.8|  6|167.6|123|3.92|3.44|18.9|  1|  0|   4|   4|\n",
            "| Merc 450SE|16.4|  8|275.8|180|3.07|4.07|17.4|  0|  0|   3|   3|\n",
            "| Merc 450SL|17.3|  8|275.8|180|3.07|3.73|17.6|  0|  0|   3|   3|\n",
            "|Merc 450SLC|15.2|  8|275.8|180|3.07|3.78|18.0|  0|  0|   3|   3|\n",
            "+-----------+----+---+-----+---+----+----+----+---+---+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2 - User Defined Functions\n",
        "In this notebook, we created a UDF to convert weight from imperial to metric units. Now for this exercise, please create a pandas UDF to convert the `mpg` column to `kmpl` (kilometers per liter). You can use the conversion factor of 0.425.\n"
      ],
      "metadata": {
        "id": "JPz46OHn4dYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code block for learners to answer\n",
        "from pyspark.sql.functions import pandas_udf\n",
        "\n",
        "@pandas_udf(\"float\")\n",
        "def convert_mileage(s: pd.Series) -> pd.Series:\n",
        "    # The formula for converting from imperial to metric tons\n",
        "    return s * 0.425\n",
        "\n",
        "spark.udf.register(\"convert_mileage\", convert_mileage)\n",
        "\n",
        "spark.sql(\"SELECT *, mpg AS mpg, convert_mileage(mpg) as kmpl FROM cars\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ncyCo0z4fEh",
        "outputId": "9b4a2080-7871-4d14-f97e-4a3dd76a3d57"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+----+-------+\n",
            "|               name| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb| mpg|   kmpl|\n",
            "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+----+-------+\n",
            "|          Mazda RX4|21.0|  6|160.0|110| 3.9| 2.62|16.46|  0|  1|   4|   4|21.0|  8.925|\n",
            "|      Mazda RX4 Wag|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|   4|21.0|  8.925|\n",
            "|         Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|22.8|   9.69|\n",
            "|     Hornet 4 Drive|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|   1|21.4|  9.095|\n",
            "|  Hornet Sportabout|18.7|  8|360.0|175|3.15| 3.44|17.02|  0|  0|   3|   2|18.7| 7.9475|\n",
            "|            Valiant|18.1|  6|225.0|105|2.76| 3.46|20.22|  1|  0|   3|   1|18.1| 7.6925|\n",
            "|         Duster 360|14.3|  8|360.0|245|3.21| 3.57|15.84|  0|  0|   3|   4|14.3| 6.0775|\n",
            "|          Merc 240D|24.4|  4|146.7| 62|3.69| 3.19| 20.0|  1|  0|   4|   2|24.4|  10.37|\n",
            "|           Merc 230|22.8|  4|140.8| 95|3.92| 3.15| 22.9|  1|  0|   4|   2|22.8|   9.69|\n",
            "|           Merc 280|19.2|  6|167.6|123|3.92| 3.44| 18.3|  1|  0|   4|   4|19.2|   8.16|\n",
            "|          Merc 280C|17.8|  6|167.6|123|3.92| 3.44| 18.9|  1|  0|   4|   4|17.8|  7.565|\n",
            "|         Merc 450SE|16.4|  8|275.8|180|3.07| 4.07| 17.4|  0|  0|   3|   3|16.4|   6.97|\n",
            "|         Merc 450SL|17.3|  8|275.8|180|3.07| 3.73| 17.6|  0|  0|   3|   3|17.3| 7.3525|\n",
            "|        Merc 450SLC|15.2|  8|275.8|180|3.07| 3.78| 18.0|  0|  0|   3|   3|15.2|   6.46|\n",
            "| Cadillac Fleetwood|10.4|  8|472.0|205|2.93| 5.25|17.98|  0|  0|   3|   4|10.4|   4.42|\n",
            "|Lincoln Continental|10.4|  8|460.0|215| 3.0|5.424|17.82|  0|  0|   3|   4|10.4|   4.42|\n",
            "|  Chrysler Imperial|14.7|  8|440.0|230|3.23|5.345|17.42|  0|  0|   3|   4|14.7| 6.2475|\n",
            "|           Fiat 128|32.4|  4| 78.7| 66|4.08|  2.2|19.47|  1|  1|   4|   1|32.4|  13.77|\n",
            "|        Honda Civic|30.4|  4| 75.7| 52|4.93|1.615|18.52|  1|  1|   4|   2|30.4|  12.92|\n",
            "|     Toyota Corolla|33.9|  4| 71.1| 65|4.22|1.835| 19.9|  1|  1|   4|   1|33.9|14.4075|\n",
            "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+----+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}